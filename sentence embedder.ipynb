{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import operator\n",
    "import gensim\n",
    "import scipy \n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading pre-trained common-space embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = '/Users/linda/desktop/embeddings/wiki.en.align.vec'\n",
    "tgt_path = '/Users/linda/desktop/embeddings/wiki.es.align.vec'\n",
    "nmax = 100000  \n",
    "src_model = gensim.models.KeyedVectors.load_word2vec_format(src_path,limit = nmax)\n",
    "tgt_model = gensim.models.KeyedVectors.load_word2vec_format(tgt_path,limit = nmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opening text file and transforming tokens into a list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = open(\"/Users/leonardo/desktop/embedding_align/teste2.txt\",\"r\",encoding=\"utf8\").read() #tokenized text\n",
    "text_en = text_en.split('￭')\n",
    "\n",
    "#FOR FURTHER USE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Transforming Sentences To Embeddings(short sentences examples)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(sentence):                                                                     \n",
    "    first_word = 0 \n",
    "    sentence = sentence.split(' ')\n",
    "    for word in sentence:                                 \n",
    "        if (first_word == 0):\n",
    "            word_emb = src_model[word]\n",
    "            first_word = 1\n",
    "        else:\n",
    "            word_emb = word_emb + src_model[word]   \n",
    "    return word_emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_en = 'the book is on the table'\n",
    "s1_es = 'el libro esta en la mesa'\n",
    "\n",
    "s2_en = 'wikipedia is a encyclopedia'\n",
    "s2_es = 'wikipedia es una enciclopedia'\n",
    "\n",
    "bigger_en = 'please allow me to introduce myself i am a man of wealth and taste i have been around for a long long year stole many a mans soul and faith'\n",
    "bigger_es = 'por favor deja que me presente soy un hombre de dinero y buen gusto he estado por aqui durante un largo largo año'\n",
    "\n",
    "ex1_en = transformer(s1_en)\n",
    "ex1_es = transformer(s1_es)\n",
    "\n",
    "ex2_en = transformer(s2_en)\n",
    "ex2_es = transformer(s2_es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the book is on the table\n",
      "distance: 0.6204316020011902\n",
      "similarity: 0.3795683979988098\n"
     ]
    }
   ],
   "source": [
    "distance = spatial.distance.cosine(ex1_es,ex1_en)\n",
    "similarity = 1 - distance\n",
    "print('the book is on the table')\n",
    "print('distance:',distance)\n",
    "print('similarity:',similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia is a free encyclopedia\n",
      "distance: 0.46321165561676025\n",
      "similarity: 0.5367883443832397\n"
     ]
    }
   ],
   "source": [
    "distance = spatial.distance.cosine(ex2_es,ex2_en)\n",
    "similarity = 1 - distance\n",
    "print('wikipedia is a free encyclopedia')\n",
    "print('distance:',distance)\n",
    "print('similarity:',similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sympathy for the devil->\n",
      "distance: 0.4724946618080139\n",
      "similarity: 0.5275053381919861\n"
     ]
    }
   ],
   "source": [
    "distance = spatial.distance.cosine(transformer(bigger_en),transformer(bigger_es))\n",
    "similarity = 1 - distance\n",
    "print('sympathy for the devil->')\n",
    "print('distance:',distance)\n",
    "print('similarity:',similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
